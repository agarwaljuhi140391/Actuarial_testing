import numpy as np
try:
	import cupy as cp
except ImportError:
	pass
import inspect
import binascii
import importlib
import os
from pathlib import Path
from src import dais
from numpy import int32, int64, float64
from numba import prange,njit,cuda

class CompiledFunction:
	debug=False
	timeloop_template="""
#THIS CODE IS AUTO-GENERATED by timeloop_tempate, DO NOT DIRECTLY EDIT UNLESS YOU KNOW WHAT YOU ARE DOING!

from numba import njit, void, prange
import numpy as np
import math
from numpy import float64, int32, int64

@njit(nogil=True, cache=True)
{funcstring}

@njit(nogil=True, parallel=True, cache=True)
def wrapped_{funcname}({vars}):
	arr_{funcname}=np.zeros({sizing_var}.shape,dtype={dtype})
	for y in prange({sizing_var}.shape[0]):
		for t in range({sizing_var}.shape[1]):
			arr_{funcname}[y,t]={funcname}({args})
	return arr_{funcname}
"""
	simple_template="""
#THIS CODE IS AUTO-GENERATED by simple_template, DO NOT DIRECTLY EDIT UNLESS YOU KNOW WHAT YOU ARE DOING!

from numba import njit, void, prange
import numpy as np
import math
from numpy import float64, int32, int64

@njit(nogil=True, cache=True)
{funcstring}

@njit(nogil=True, parallel=True, cache=True)
def wrapped_{funcname}({vars}):
	arr_{funcname}=np.zeros(({sizing_var}.shape[0],1),dtype={dtype})
	for y in prange({sizing_var}.shape[0]):
		arr_{funcname}[y,0]={funcname}({args})
	return arr_{funcname}
"""
# 	complex_template="""
# #THIS CODE IS AUTO-GENERATED by complex_template, DO NOT DIRECTLY EDIT UNLESS YOU KNOW WHAT YOU ARE DOING!
# 
# from numba import njit, void, prange
# import numpy as np
# from numpy import float64, int32, int64
# from dais.models.simple_dispatcher import irr_est
# 
# @njit(nogil=True, parallel=True, cache=True)
# {funcstring}
# 
# def wrapped_{funcname}({reduced_vars}):
# 	arr_{funcname}=np.zeros(({shape}),dtype={dtype})
# 	{funcname}({reduced_vars},arr_{funcname})
# 	return arr_{funcname}
# """
	complex_template="""
#THIS CODE IS AUTO-GENERATED by complex_template, DO NOT DIRECTLY EDIT UNLESS YOU KNOW WHAT YOU ARE DOING!

from numba import njit, void, prange
import numpy as np
import math
from numpy import float64, int32, int64
from dais.models.simple_dispatcher import irr_est

@njit(nogil=True, cache=True)
{funcstring}

@njit(nogil=True, parallel=True, cache=True)
def wrapped_{funcname}({reduced_vars}):
	arr_{funcname}=np.zeros(({shape}),dtype={dtype})
	for y in prange(arr_{funcname}.shape[0]):
		{funcname}({reduced_vars2},arr_{funcname}[y,:])
	return arr_{funcname}
"""
	# derivedcomplex_template="""
# THIS CODE IS AUTO-GENERATED by derivedcomplex_template, DO NOT DIRECTLY EDIT UNLESS YOU KNOW WHAT YOU ARE DOING!
#
# from numba import njit, void, prange
# import numpy as np
# from numpy import float64, int32, int64
#
# @njit(nogil=True, parallel=True, cache=True)
# {funcstring}
#
# def wrapped_{funcname}({reduced_vars}):
	# {array_creation}
	# {funcname}({reduced_vars},{created_arrs})
	# return {dict_of_arrays}
# """
	derivedcomplex_template="""
#THIS CODE IS AUTO-GENERATED by derivedcomplex_template, DO NOT DIRECTLY EDIT UNLESS YOU KNOW WHAT YOU ARE DOING!

from numba import njit, void, prange
import numpy as np
import math
from numpy import float64, int32, int64

@njit(nogil=True, cache=True)
{funcstring}

@njit(nogil=True, parallel=True, cache=True)
def wrapped_{funcname}({reduced_vars}):
	{array_creation}
	for y in prange({shape}):
		{funcname}({reduced_vars2},{created_arrs})
	return {dict_of_arrays}
"""

	executors={}


	permitted_types=set(['Derived','DerivedComplex','DerivedBond'])

	def __init__(self,funcnode,argnodes,classname,cachepath=None,debug=False):
		assert funcnode.source_type in self.permitted_types
		self.debug=debug
		
		self.executors.update({
			 'DerivedComplex':self._aFC_DerivedComplex
			,'j':self._aFC_j
			,'v2':self._aFC_v2
			,'v1':self._aFC_v1
		})
		
		self.funcnode=funcnode
		self.argnodes=argnodes
		if cachepath:
			assert os.path.isdir(cachepath)
			self.cachepath=cachepath
			self.modulepath='dais.__dais_cache__.{}'.format(self.funcnode.name) #What's the right thing to do here? Set syspath?! Not permit this option?
		else:
			path=os.path.normpath(os.path.join(inspect.getfile(dais),'..','__dais_cache__',classname))
# 			print('FuncNode: ',funcnode,path)
			Path(path).mkdir(parents=True,exist_ok=True)
			self.cachepath = path
			self.modulepath='dais.__dais_cache__.{}.{}'.format(classname,self.funcnode.name)
		assembledfile=self.assembleFileContents()
		self.cache_hit=self.compare(assembledfile,self.readCacheContent())
		if not self.cache_hit:
			print('Caching: ',self.funcnode.name)
			self.write_cache(assembledfile)
			print('Initialising: ',self.funcnode.name)
			self.initialise_cache()
		mod=importlib.import_module(self.modulepath)
		importlib.reload(mod)
		self.numba_func=getattr(mod,'wrapped_'+self.funcnode.name)
		
	def write_cache(self,assembledfile):
		with open(os.path.join(self.cachepath,self.funcnode.name+'.py'),'wb') as f:
			f.write(assembledfile)
		
	def initialise_cache(self):
		mod=importlib.import_module(self.modulepath)
		importlib.reload(mod)
		numba_func=getattr(mod,'wrapped_'+self.funcnode.name)
		args=[]
		for arg in self.argnodes:
			args.append(np.zeros((3,3),dtype=arg.attr['type']))
			# if arg.name=='T':
				# args[-1].setflags(write=False)
		testrun=numba_func(*args)
		# print(self.funcnode.name,numba_func.signatures)
	
	def compare(self,a,b):
		crc_a=binascii.crc32(a)
		crc_b=binascii.crc32(b)
		if crc_a==crc_b:
			return True
		else:
			return False
		
	def readCacheContent(self):
		try:
			with open(os.path.join(self.cachepath,self.funcnode.name+'.py'),'rb') as f:
				cachecontent=f.read()
			return cachecontent
		except (NameError,FileNotFoundError) as e:
			return b''

	def _aFC_DerivedComplex(self):
		if self.debug:
			print("In aFC_DC: ",self.funcnode.name)
		assert self.funcnode.source_type=='DerivedComplex'
		args_create=[]
		args_call=[]
		args_return=[]
		outvars=self.funcnode.attr['outvars'].keys()
		ordered_outvars=sorted(outvars,key=lambda x: self.funcnode.attr['outvars'][x]['order'])
		for arg in ordered_outvars:
			sizing_var_candidates=[argnode.name for argnode in self.argnodes if argnode.attr['shape']==self.funcnode.attr['outvars'][arg]['shape']]
			sv=sizing_var_candidates[0]
			args_create.append("arr_{argname}=np.zeros({sizing_var}.shape,{dtype})".format(sizing_var=sv,argname=arg,dtype=self.funcnode.attr['outvars'][arg]['type']))
			args_call.append("arr_{argname}".format(argname=arg))
			args_return.append("'{argname}': arr_{argname}".format(argname=arg))
		reduced_vars2=[]
		for argnode in self.argnodes:
			if argnode.source_type=='TableBond':
				reduced_vars2.append(argnode.name)
			else:
				reduced_vars2.append(argnode.name+'[y,:]')
		template_inputs={'funcname': self.funcnode.name
						,'array_creation': "\n\t".join(args_create)
						,'funcstring':"".join([line[1:] for line in self.funcnode.get_func_string().splitlines(keepends=True) if line[0] != '#'])
						,'reduced_vars':",".join([argnode.name for argnode in self.argnodes])
						,'shape':'{}.shape[0]'.format(sv)
						,'reduced_vars2':",".join(reduced_vars2)
						,'created_arrs':",".join([arg+'[y,:]' for arg in args_call])
						,'dict_of_arrays':"{"+",".join(args_return)+"}"
		}
		return self.derivedcomplex_template.format(**template_inputs)

	# def _aFC_DerivedComplex(self):
		# assert self.funcnode.source_type=='DerivedComplex'
		# args_create=[]
		# args_call=[]
		# args_return=[]
		# outvars=self.funcnode.attr['outvars'].keys()
		# ordered_outvars=sorted(outvars,key=lambda x: self.funcnode.attr['outvars'][x]['order'])
		# for arg in ordered_outvars:
			# sizing_var_candidates=[argnode.name for argnode in self.argnodes if argnode.attr['shape']==self.funcnode.attr['outvars'][arg]['shape']]
			# sv=sizing_var_candidates[0]
			# args_create.append("arr_{argname}=np.zeros({sizing_var}.shape,{dtype})".format(sizing_var=sv,argname=arg,dtype=self.funcnode.attr['outvars'][arg]['type']))
			# args_call.append("arr_{argname}".format(argname=arg))
			# args_return.append("'{argname}': arr_{argname}".format(argname=arg))
		# template_inputs={'funcname': self.funcnode.name
						# ,'array_creation': "\n\t".join(args_create)
						# ,'funcstring':"".join([line[1:] for line in self.funcnode.get_func_string().splitlines(keepends=True) if line[0] != '#'])
						# ,'reduced_vars':",".join([argnode.name for argnode in self.argnodes])
						# ,'created_arrs':",".join(args_call)
						# ,'dict_of_arrays':"{"+",".join(args_return)+"}"
		# }
		# return self.derivedcomplex_template.format(**template_inputs)
		
	def _aFC_j(self):
		if self.debug:
			print("In aFC_j: ",self.funcnode.name)
		sizing_var_candidates=[argnode.name for argnode in self.argnodes if argnode.attr['shape']==self.funcnode.attr['shape']]
		if len(sizing_var_candidates)>0:
			sv=sizing_var_candidates[0]
			shape="{sv}.shape[0],{sv}.shape[1]".format(sv=sv)
		else:
			sv=[argnode.name for argnode in self.argnodes if argnode.attr['shape'] >0][0]
			shape="{sv}.shape[0],1".format(sv=sv)
		reduced_vars2=[]
		for argnode in self.argnodes:
			if argnode.source_type=='TableBond':
				reduced_vars2.append(argnode.name)
			else:
				reduced_vars2.append(argnode.name+'[y,:]')
		template_inputs={'funcname': self.funcnode.name
						,'dtype':np.dtype(self.funcnode.attr['type']).name
						,'funcstring':"".join([line[1:] for line in self.funcnode.get_func_string().splitlines(keepends=True) if line[0] != '#'])
						,'reduced_vars':",".join([argnode.name for argnode in self.argnodes])
						,'reduced_vars2':",".join(reduced_vars2)
						,'shape':"{shape}".format(shape=shape)
						}
		return self.complex_template.format(**template_inputs)
		
	def _aFC_v2(self):
		if self.debug:
			print("In aFC_v2: ",self.funcnode.name)
		args=[]
		for argnode in self.argnodes:
			if self.debug:
				print(argnode)
			if argnode.attr['shape']==2:
				args.append(argnode.name+'[y,t]')
			elif argnode.attr['shape']==0:
				args.append(argnode.name+'[0,0]')
			else:
				args.append(argnode.name+'[y,0]')
		template_inputs={'funcname': self.funcnode.name
						,'dtype':np.dtype(self.funcnode.attr['type']).name
						,'funcstring': "".join([line[1:] for line in self.funcnode.get_func_string().splitlines(keepends=True)])
						,'vars': ",".join([argnode.name for argnode in self.argnodes])
						,'args': ",".join(args)
						,'sizing_var': [argnode.name for argnode in self.argnodes if argnode.attr['shape']==2][0]}
		return self.timeloop_template.format(**template_inputs)
		
	def _aFC_v1(self):
		if self.debug:
			print("In aFC_v1: ",self.funcnode.name)
		args=[]
		for argnode in self.argnodes:
			assert argnode.attr['shape'] != 2
			if argnode.attr['shape']==1:
				args.append(argnode.name+'[y,0]')
			else:
				args.append(argnode.name+'[0,0]')
		template_inputs={'funcname': self.funcnode.name
						,'dtype':np.dtype(self.funcnode.attr['type']).name
						,'funcstring': "".join([line[1:] for line in self.funcnode.get_func_string().splitlines(keepends=True)])
						,'vars': ",".join([argnode.name for argnode in self.argnodes])
						,'args': ",".join(args)
						,'sizing_var': [argnode.name for argnode in self.argnodes if argnode.attr['shape']==1][0]}
		return self.simple_template.format(**template_inputs)
	
	def assembleFileContents(self):
		if self.funcnode.source_type=='DerivedComplex':
			filecontents=self.executors['DerivedComplex']()
		elif self.funcnode.attr['numba']=='j':
			filecontents=self.executors['j']()
		elif self.funcnode.attr['numba']=='v':
			if self.funcnode.attr['shape']==2:
				filecontents=self.executors['v2']()
			else:
				filecontents=self.executors['v1']()
		return filecontents.encode('UTF-8')

class BondCompiledFunction(CompiledFunction):
	pass
	
class GPUCompiledFunction(CompiledFunction):
	timeloop_template="""
#THIS CODE IS AUTO-GENERATED by timeloop_tempate, DO NOT DIRECTLY EDIT UNLESS YOU KNOW WHAT YOU ARE DOING!

from numba import njit, void, prange, cuda
import numpy as np
import cupy as cp
import math
from numpy import float64, int32, int64

@cuda.jit(device=True)
{funcstring}

@cuda.jit
def kernel_{funcname}({vars},arr_{funcname}):
	y,t=cuda.grid(2)
	if y < {sizing_var}.shape[0]:
		if t < {sizing_var}.shape[1]:
			arr_{funcname}[y,t]={funcname}({args})

def wrapped_{funcname}({vars}):
	print('Executing on GPU: {funcname}')
	stream=cuda.stream()
	for var in [{vars}]:
		if type(var)==cp.ndarray:
			pass
		else:
			var=cp.asarray(var)
	arr_{funcname}=cp.zeros({sizing_var}.shape,dtype={dtype})
	threadsperblock=(16,16)
	blockspergrid_y=math.ceil({sizing_var}.shape[0] / threadsperblock[0])
	blockspergrid_t=math.ceil({sizing_var}.shape[1] / threadsperblock[1])
	blockspergrid=(blockspergrid_y,blockspergrid_t)
	kernel_{funcname}[blockspergrid,threadsperblock,stream]({vars},arr_{funcname})
	stream.synchronize()
	return arr_{funcname}
"""
	derivedcomplex_template="""
#THIS CODE IS AUTO-GENERATED by derivedcomplex_template, DO NOT DIRECTLY EDIT UNLESS YOU KNOW WHAT YOU ARE DOING!

from numba import njit, void, prange,cuda
import numpy as np
import cupy as cp
import math
from numpy import float64, int32, int64

@cuda.jit(device=True)
{funcstring}

@cuda.jit
def kernel_{funcname}({reduced_vars},{created_arrs2}):
	y=cuda.grid(1)
	if y < {shape}.shape[0]:
		{funcname}({reduced_vars2},{created_arrs})

def wrapped_{funcname}({reduced_vars}):
	print('Executing on GPU: {funcname}')
	stream=cuda.stream()
	for var in [{reduced_vars}]:
		if type(var)==cp.ndarray:
			pass
		else:
			var=cp.asarray(var)
	{array_creation}
	threadsperblock=32
	blockspergrid=math.ceil({shape}.shape[0] / threadsperblock)
	kernel_{funcname}[blockspergrid,threadsperblock,stream]({reduced_vars},{created_arrs2})
	stream.synchronize()
	return {dict_of_arrays}
"""
	simple_template="""
#THIS CODE IS AUTO-GENERATED by simple_template, DO NOT DIRECTLY EDIT UNLESS YOU KNOW WHAT YOU ARE DOING!

from numba import njit, void, prange, cuda
import numpy as np
import cupy as cp
import math
from numpy import float64, int32, int64

@cuda.jit(device=True)
{funcstring}

@cuda.jit
def kernel_{funcname}({vars},arr_{funcname}):
	y=cuda.grid(1)
	if y < {sizing_var}.shape[0]:
		arr_{funcname}[y,0]={funcname}({args})

def wrapped_{funcname}({vars}):
	print('Executing on GPU: {funcname}')
	stream=cuda.stream()
	for var in [{vars}]:
		if type(var)==cp.ndarray:
			pass
		else:
			var=cp.asarray(var)
	arr_{funcname}=cp.zeros({sizing_var}.shape,dtype={dtype})
	threadsperblock=32
	blockspergrid=math.ceil({sizing_var}.shape[0] / threadsperblock)
	kernel_{funcname}[blockspergrid,threadsperblock,stream]({vars},arr_{funcname})
	stream.synchronize()
	return arr_{funcname}
"""
	complex_template="""
#THIS CODE IS AUTO-GENERATED by complex_template, DO NOT DIRECTLY EDIT UNLESS YOU KNOW WHAT YOU ARE DOING!

from numba import njit, void, prange,cuda
import numpy as np
import cupy as cp
import math
from numpy import float64, int32, int64
from dais.models.simple_dispatcher import gpu_irr_est as irr_est

@cuda.jit(device=True)
{funcstring}

@cuda.jit
def kernel_{funcname}({reduced_vars},arr_{funcname}):
	y=cuda.grid(1)
	if y < arr_{funcname}.shape[0]:
		{funcname}({reduced_vars2},arr_{funcname}[y,:])

def wrapped_{funcname}({reduced_vars}):
	print('Executing on GPU: {funcname}')
	stream=cuda.stream()
	for var in [{reduced_vars}]:
		if type(var)==cp.ndarray:
			pass
		else:
			var=cp.asarray(var)
	arr_{funcname}=cp.zeros(({shape}),dtype={dtype})
	threadsperblock=32
	blockspergrid=math.ceil(arr_{funcname}.shape[0] / threadsperblock)
	kernel_{funcname}[blockspergrid,threadsperblock,stream]({reduced_vars},arr_{funcname})
	stream.synchronize()
	return arr_{funcname}
"""

	def initialise_cache(self):
		mod=importlib.import_module(self.modulepath)
		importlib.reload(mod)
		numba_func=getattr(mod,'wrapped_'+self.funcnode.name)
		args=[]
		for arg in self.argnodes:
			args.append(cp.zeros((3,3),dtype=arg.attr['type']))
		testrun=numba_func(*args)

	def _aFC_v2(self):
		print("In aFC_v2 GPU: ",self.funcnode.name)
		args=[]
		for argnode in self.argnodes:
			print (argnode)
			if argnode.attr['shape']==2:
				args.append(argnode.name+'[y,t]')
			elif argnode.attr['shape']==0:
				args.append(argnode.name+'[0,0]')
			else:
				args.append(argnode.name+'[y,0]')
		template_inputs={'funcname': self.funcnode.name
						,'dtype':np.dtype(self.funcnode.attr['type']).name
						,'funcstring': "".join([line[1:] for line in self.funcnode.get_func_string().splitlines(keepends=True)])
						,'vars': ",".join([argnode.name for argnode in self.argnodes])
						,'args': ",".join(args)
						,'sizing_var': [argnode.name for argnode in self.argnodes if argnode.attr['shape']==2][0]}
		return self.timeloop_template.format(**template_inputs)

	def _aFC_DerivedComplex(self):
		print("In aFC_DC GPU: ",self.funcnode.name)
		assert self.funcnode.source_type=='DerivedComplex'
		args_create=[]
		args_call=[]
		args_return=[]
		outvars=self.funcnode.attr['outvars'].keys()
		ordered_outvars=sorted(outvars,key=lambda x: self.funcnode.attr['outvars'][x]['order'])
		for arg in ordered_outvars:
			sizing_var_candidates=[argnode.name for argnode in self.argnodes if argnode.attr['shape']==self.funcnode.attr['outvars'][arg]['shape']]
			sv=sizing_var_candidates[0]
			args_create.append("arr_{argname}=cp.zeros({sizing_var}.shape,{dtype})".format(sizing_var=sv,argname=arg,dtype=self.funcnode.attr['outvars'][arg]['type']))
			args_call.append("arr_{argname}".format(argname=arg))
# 			args_return.append("'{argname}': arr_{argname}.copy_to_host()".format(argname=arg))
			args_return.append("'{argname}': arr_{argname}".format(argname=arg))
		reduced_vars2=[]
		for argnode in self.argnodes:
			if argnode.source_type=='TableBond':
				reduced_vars2.append(argnode.name)
			else:
				reduced_vars2.append(argnode.name+'[y,:]')
		template_inputs={'funcname': self.funcnode.name
						,'array_creation': "\n\t".join(args_create)
						,'funcstring':"".join([line[1:] for line in self.funcnode.get_func_string().splitlines(keepends=True) if line[0] != '#'])
						,'reduced_vars':",".join([argnode.name for argnode in self.argnodes])
						,'shape':'{}'.format(sv)
						,'reduced_vars2':",".join(reduced_vars2)
						,'created_arrs':",".join([arg+'[y,:]' for arg in args_call])
						,'created_arrs2':",".join([arg for arg in args_call])
						,'dict_of_arrays':"{"+",".join(args_return)+"}"
		}
		return self.derivedcomplex_template.format(**template_inputs)
